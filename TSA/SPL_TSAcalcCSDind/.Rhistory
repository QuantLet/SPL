colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))
temp =   (acf[1:nrow(acf), 2] -
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /
getRunningSD(acf, ws)
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /
getRunningSD(skew, ws)
W2   = data.frame(W2, temp)
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(i, ""%&%sentiment%&%"_"%&%i%&%".csv")
}
# Tidy up
rm(max.ws, n, temp, ws, i)
}
# end of file
source(
rm(list = ls())
# Load required packages
if(!require("tseries")) install.packages("tseries")
library("tseries")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Repeat whole analysis for positive as well as negative sentiment share
for(sentiment in c("positive", "negative")){
# Get data
ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Check for missing values
if(any(is.na(ts))) {
stop(paste("There are missing values present in this time series.",
"Interpolate raw data first.", sep = " "))
}
# Test for stationarity
if(adf.test(ts)$p.value > 0.05) {
print(paste("Test for stationarity could not reject H0:",
"Time series has a unit root.",
"Consider detrending your time series.",
sep = " "))
q <- readline("Would you like to proceed anyway? (Y/N)")
if(regexpr(q, "y", ignore.case = TRUE) == 1){
next
} else {
break
}
}
### Calculate rolling window statistics for ts ###
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))
temp =   (acf[1:nrow(acf), 2] -
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /
getRunningSD(acf, ws)
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /
getRunningSD(skew, ws)
W2   = data.frame(W2, temp)
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(i, ""%&%sentiment%&%"_"%&%i%&%".csv")
}
# Tidy up
rm(max.ws, n, temp, ws, i)
}
# end of file
)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source(
rm(list = ls())
# Load required packages
if(!require("tseries")) install.packages("tseries")
library("tseries")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Repeat whole analysis for positive as well as negative sentiment share
for(sentiment in c("positive", "negative")){
# Get data
ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Check for missing values
if(any(is.na(ts))) {
stop(paste("There are missing values present in this time series.",
"Interpolate raw data first.", sep = " "))
}
# Test for stationarity
if(adf.test(ts)$p.value > 0.05) {
print(paste("Test for stationarity could not reject H0:",
"Time series has a unit root.",
"Consider detrending your time series.",
sep = " "))
q <- readline("Would you like to proceed anyway? (Y/N)")
if(regexpr(q, "y", ignore.case = TRUE) == 1){
next
} else {
break
}
}
### Calculate rolling window statistics for ts ###
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))
temp =   (acf[1:nrow(acf), 2] -
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /
getRunningSD(acf, ws)
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /
getRunningSD(skew, ws)
W2   = data.frame(W2, temp)
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(i, ""%&%sentiment%&%"_"%&%i%&%".csv")
}
# Tidy up
rm(max.ws, n, temp, ws, i)
}
# end of file
)
source(TSAcalcCSDindicators)
source("TSAcalcCSDindicators.R")
d
source("TSAcalcCSDindicators.R")
?break
regexpr(q, "y", ignore.case = TRUE)
regexpr(q, "y", ignore.case = TRUE) != 1
?regexpr
regexpr(q, "y", ignore.case = TRUE)
regexpr(q, 'y', ignore.case = TRUE)
q <- "n"
regexpr(q, 'y', ignore.case = TRUE)
q <- "y"
regexpr(q, 'y', ignore.case = TRUE)
q <- "blabla"
regexpr(q, 'y', ignore.case = TRUE)
regexpr(eval(q), 'y', ignore.case = TRUE)
regexpr(q, 'y', ignore.case = TRUE)
regexpr(q, 'y', ignore.case = TRUE) != 1
q <- "y"
regexpr(q, 'y', ignore.case = TRUE) != 1
rm(list = ls())
# Load required packages
if(!require("tseries")) install.packages("tseries")
library("tseries")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Repeat whole analysis for positive as well as negative sentiment share
for(sentiment in c("positive", "negative")){
# Get data
ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Check for missing values
if(any(is.na(ts))) {
stop(paste("There are missing values present in this time series.",
"Interpolate raw data first.", sep = " "))
}
# Test for stationarity
if(adf.test(ts)$p.value > 0.05) {
print(paste("Test for stationarity could not reject H0:",
"Time series has a unit root.",
"Consider detrending your time series.",
sep = " "))
q <- readline("Would you like to proceed anyway? (Y/N)")
if(regexpr(q, 'y', ignore.case = TRUE) != 1){
break
}
}
### Calculate rolling window statistics for ts ###
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))
temp =   (acf[1:nrow(acf), 2] -
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /
getRunningSD(acf, ws)
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /
getRunningSD(skew, ws)
W2   = data.frame(W2, temp)
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(i, ""%&%sentiment%&%"_"%&%i%&%".csv")
}
# Tidy up
rm(max.ws, n, temp, ws, i)
}
# end of file
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
ts = getData("tweets_raw.csv")
plot(ts, type = "l")
plot(ts[[2]], type = "l")
#######################################################
#######################################################
##                                                   ##
##  WARNING: This script has to be run  by clicking  ##
##           on the source button on the upper       ##
##           right corner of this window             ##
##                                                   ##
#######################################################
#######################################################
rm(list = ls())
# Load required packages
if(!require("tseries")) install.packages("tseries")
library("tseries")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Repeat whole analysis for positive as well as negative sentiment share
for(sentiment in c("positive", "negative")){
# Get data
ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Check for missing values
if(any(is.na(ts))) {
stop(paste("There are missing values present in this time series.",
"Interpolate raw data first.", sep = " "))
}
# Test for stationarity
if(adf.test(ts)$p.value > 0.05) {
print(paste("Test for stationarity could not reject H0:",
"Time series has a unit root.",
"Consider detrending your time series.",
sep = " "))
q <- readline("Would you like to proceed anyway? (Y/N)")
if(regexpr(q, 'y', ignore.case = TRUE) != 1){
break
}
}
### Calculate rolling window statistics for ts ###
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))
temp =   (acf[1:nrow(acf), 2] -
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /
getRunningSD(acf, ws)
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /
getRunningSD(skew, ws)
W2   = data.frame(W2, temp)
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(i, ""%&%sentiment%&%"_"%&%i%&%".csv")
}
# Tidy up
rm(max.ws, n, temp, ws, i)
}
# end of file
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
View(flag)
i <- "acf"
x <- as.name(i)
x
write.csv(x, ""%&%sentiment%&%"_"%&%i%&%".csv")
x <- eval(i)
x <- eval(paste(i))
paste(i)
eval(paste(i))
get(i)
x <- get(i)
write.csv(x, ""%&%sentiment%&%"_"%&%i%&%".csv")
write.csv(get(i), ""%&%sentiment%&%"_"%&%i%&%".csv")
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
source('~/Documents/01 Studium/02 Master/4. Semester/01 Statistical Programming Languages/04 Group project/spl/02 Quantlets/SPL_TSAcalcCSDind/TSAcalcCSDindicators.R', echo=TRUE)
regexpr(q, 'y', ignore.case = TRUE
)
regexpr(q, 'y', ignore.case = TRUE) != 1
#######################################################
#######################################################
##                                                   ##
##  WARNING: This script has to be run by clicking   ##
##           on the source button on the upper       ##
##           right corner of this window             ##
##                                                   ##
#######################################################
#######################################################
rm(list = ls())
# Load required packages
if(!require("tseries")) install.packages("tseries")
library("tseries")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Repeat whole analysis for positive as well as negative sentiment share
for(sentiment in c("positive", "negative")){
# Get data
ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Check for missing values
if(any(is.na(ts))) {
stop(paste("There are missing values present in this time series.",
"Interpolate raw data first.", sep = " "))
}
# Test for stationarity
if(adf.test(ts)$p.value > 0.05) {
print(paste("Test for stationarity could not reject H0:",
"Time series has a unit root.",
"Consider detrending your time series.",
sep = " "))
q <- readline("Would you like to proceed anyway? (Y/N)")
if(regexpr(q, 'y', ignore.case = TRUE) != 1){
break
}
}
### Calculate rolling window statistics for ts ###
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var  = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))
temp =   (acf[1:nrow(acf), 2] -
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /
getRunningSD(acf, ws)
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /
getRunningSD(skew, ws)
W2   = data.frame(W2, temp)
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(get(i), ""%&%sentiment%&%"_"%&%i%&%".csv")
}
# Tidy up
rm(max.ws, n, temp, ws, i)
}
# end of file
regexpr(q, 'y', ignore.case = TRUE) != 1
q <- "n"
regexpr(q, 'y', ignore.case = TRUE) != 1
q <- ""
regexpr(q, 'y', ignore.case = TRUE) != 1
