ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Repeat whole analysis for positive as well as negative sentiment share
for(sentiment in c("positive", "negative")){
# Get data
ts =  getData("tweets_raw.csv", sentiment)[[2]]
# Check for missing values
if(any(is.na(ts))) {
stop(paste("There are missing values present in this time series.",
"Interpolate raw data first.", sep = " "))
}
# Test for stationarity
if(adf.test(ts)$p.value > 0.05) {
print(paste("Test for stationarity could not reject H0:",
"Time series has a unit root. Consider detrending your time series.",
sep = " "))
q <- readline("Would you like to proceed anyway? (Y/N)")
if(regexpr(q, 'y', ignore.case = TRUE) == 1){
next
} else {
break
}
}
### Calculate rolling window statistics for ts ###
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf  = c(1:length(ts))                                                       # Initialize df for autocorrelations for each
# moving window (rows) and different window sizes (cols)
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)                                       # Calculate vector with autocorrelations for window size i
acf  = data.frame(acf, c(rep(NA, i-1), temp))                              # Write results for window size i in data frame and add i-1
# NAs at start of vector
colnames(acf)[ncol(acf)] = "acf_ws"%&%i                                    # Rename last added column according to window size
}
# Variance
var  = c(1:length(ts))                                                       # Same procedure for variance and skewness as above
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
# W_2 measure
W2 = c(1:length(ts))
for(ws in 3:max.ws) {
n    = c(rep(NA, (ws-1)), 1:(length(ts)-ws+1))                    # Vector of n with which to divide for averages
temp =    (acf[1:nrow(acf), 2] -                                             # Standardized deviation of the current window
c(rep(NA, ws-1), cumsum(acf[ws:nrow(acf) , 2])) / n) /        # autocorrelation to the mean of the autocor-
getRunningSD(acf, ws)                                         # relations of all previous windows
+ (var[1:nrow(var), 2] -
c(rep(NA, ws-1), cumsum(var[ws:nrow(var) , 2])) / n) /      # Standardized deviation of variance
getRunningSD(var, ws)
+ (skew[1:nrow(skew), 2] -
c(rep(NA, ws-1), cumsum(skew[ws:nrow(skew) , 2])) / n) /   # Standardized deviation of skewness
getRunningSD(skew, ws)
W2 = data.frame(W2, temp)
# Name columns for W2
colnames(W2)[ncol(W2)] = "W2_ws"%&%ws
}
# Create data frame containing running mean/standard deviation
# of W2 measure to identify CSD areas
flag = flagCSD(W2)
# Tidy up
rm(max.ws, n, temp, ws, i)
# Write out data frames
for(i in c("acf", "var", "skew", "flag", "W2", "ts")){
write.csv(i, ""%&%sentiment%&%"_"%&%i%&%".csv")
}
}
list.files(pattern = "(TSAfun_){1}.*.R")
setwd("../SPL_TSAtestFUNmw")
list.files(pattern = "(TSAfun_){1}.*.R")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
rm(list = ls())
# Load required packages
if(!require("zoo")) install.packages("zoo")
library("zoo")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Simulate time series
set.seed(20180705)
sim.ma = arima.sim(list(ma = c(0.6, -0.4)), n = 100000)
window = 10
# Test differences in running time and deviation between results
# (this may take a few seconds depending on your hardware)
compareFunctions(getMovingWindowACF,  rollapplyACF,  sim.ma, window)
compareFunctions(getMovingWindowVAR,  rollapplyVAR,  sim.ma, window)
compareFunctions(getMovingWindowSKEW, rollapplySKEW, sim.ma, window)
# Get data
ts = getData("data/tweets_raw.csv")[[2]]
# Get data
ts = getData("tweets_raw.csv")[[2]]
# Set tolerance for deviations between results (Smaller deviations
# are assumed to be due to accumulated rounding differences)
tol = 1e-10
# Iterate through window sizes
for(ws in 3:floor(length(ts)/2)) {
# Lag-1-autocorrelation
test_acf  = getMovingWindowACF(ts, w = ws)
test_acf2 = rollapply(ts, width = ws, FUN = function(x){
acf(x, plot = FALSE, lag.max = 1)$acf[1+1]
})
print(paste("Window size "%&%ws%&%":"))
print(paste("Lag-1-autocorrelation ->",
if(max(abs(test_acf-test_acf2)) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(test_acf-test_acf2)))
} else {
paste("All deviations are smaller than "%&%tol)
}))
# Variance
test_var  = getMovingWindowVAR(ts, w = ws)
test_var2 = rollapply(ts, width = ws, var)
print(paste("Variance              ->",
if(max(abs(test_var-test_var2)) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(test_var-test_var2)))
} else {
paste("All deviations are smaller than "%&%tol)
}))
# Skewness
test_skew  = getMovingWindowSKEW(ts, w = ws)
test_skew2 = rollapply(ts, width = ws, skewness)
print(paste("Skewness              ->",
if(max(abs(test_skew-test_skew2)) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(test_skew-test_skew2)))
} else {
paste("All deviations are smaller than "%&%tol)
}))
# Tidy up after each window size
rm(ws, list = ls(pattern = "test_"))
}
# Test gain in computing time from using getMovingWindow* funcitons vs rollapply
# (this may take a few seconds depending on your hardware)
compareTime(ts, getMovingWindowACF,  rollapplyACF)
compareTime(ts, getMovingWindowVAR,  rollapplyVAR)
compareTime(ts, getMovingWindowSKEW, rollapplySKEW)
setwd("../SPL_TSAtestFUNrSD")
rm(list = ls())
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Get data
ts = getData("tweets_raw.csv")[[2]]
#### Calculate rolling window statistics for ts ####
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew  = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
#### Test getRunningSD function ####
# Test whether getRunningSD function and for-loop calculating standard
# deviation with standard package functions generate same results
# Set tolerance for deviations between results (Smaller deviations
# are assumed to be due to accumulated rounding differences)
tol = 1e-15
# Iterate through window sizes
for(ws in 3:floor(length(ts)/2)) {
# Lag-1-autocorrelation
run_sd_acf  = getRunningSD(acf, ws)
run_sd_acf2 = rep(NA, nrow(acf))
for (i in (ws+1):nrow(acf)) {
run_sd_acf2[i] = sd(acf[ws:i, ws-1])
}
print(paste("Window size "%&%ws%&%":"))
print(paste("Lag-1-autocorrelation ->",
if(max(abs(run_sd_acf-run_sd_acf2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(run_sd_acf-run_sd_acf2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Variance
run_sd_var  = getRunningSD(var, ws)
run_sd_var2 = rep(NA, nrow(var))
for (i in (ws+1):nrow(var)) {
run_sd_var2[i] = sd(var[ws:i, ws-1])
}
print(paste("Variance              ->",
if(max(abs(run_sd_var-run_sd_var2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(run_sd_var-run_sd_var2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Skewness
run_sd_skew  = getRunningSD(skew, ws)
run_sd_skew2 = rep(NA, nrow(skew))
for (i in (ws+1):nrow(skew)) {
run_sd_skew2[i] = sd(skew[ws:i, ws-1])
}
print(paste("Skewness              ->",
if(max(abs(run_sd_skew-run_sd_skew2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(run_sd_skew-run_sd_skew2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Tidy up after each window size
rm(ws, list = ls(pattern = "run_"))
}
rm(list = ls())
# Load required packages
if(!require("zoo")) install.packages("zoo")
library("zoo")
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
#### TEST 1: Simulated data ####
# Simulate time series
set.seed(20180705)
sim.ma = arima.sim(list(ma = c(0.6, -0.4)), n = 100000)
window = 10
# Test differences in running time and deviation between results
# (this may take a few seconds depending on your hardware)
compareFunctions(getMovingWindowACF,  rollapplyACF,  sim.ma, window)
compareFunctions(getMovingWindowVAR,  rollapplyVAR,  sim.ma, window)
compareFunctions(getMovingWindowSKEW, rollapplySKEW, sim.ma, window)
#### TEST 2: Empirical time series (sentiment data from Tweets) ####
# Get data
ts = getData("tweets_raw.csv")[[2]]
# Test whether getMovingWindow* functions and rollapply approach
# generate same results
# Set tolerance for deviations between results (Smaller deviations
# are assumed to be due to accumulated rounding differences)
tol = 1e-10
# Iterate through window sizes
for(ws in 3:floor(length(ts)/2)) {
# Lag-1-autocorrelation
test_acf  = getMovingWindowACF(ts, w = ws)
test_acf2 = rollapply(ts, width = ws, FUN = function(x){
acf(x, plot = FALSE, lag.max = 1)$acf[1+1]
})
print(paste("Window size "%&%ws%&%":"))
print(paste("Lag-1-autocorrelation ->",
if(max(abs(test_acf-test_acf2)) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(test_acf-test_acf2)))
} else {
paste("All deviations are smaller than "%&%tol)
}))
# Variance
test_var  = getMovingWindowVAR(ts, w = ws)
test_var2 = rollapply(ts, width = ws, var)
print(paste("Variance              ->",
if(max(abs(test_var-test_var2)) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(test_var-test_var2)))
} else {
paste("All deviations are smaller than "%&%tol)
}))
# Skewness
test_skew  = getMovingWindowSKEW(ts, w = ws)
test_skew2 = rollapply(ts, width = ws, skewness)
print(paste("Skewness              ->",
if(max(abs(test_skew-test_skew2)) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(test_skew-test_skew2)))
} else {
paste("All deviations are smaller than "%&%tol)
}))
# Tidy up after each window size
rm(ws, list = ls(pattern = "test_"))
}
# Test gain in computing time from using getMovingWindow* funcitons vs rollapply
# (this may take a few seconds depending on your hardware)
compareTime(ts, getMovingWindowACF,  rollapplyACF)
compareTime(ts, getMovingWindowVAR,  rollapplyVAR)
compareTime(ts, getMovingWindowSKEW, rollapplySKEW)
# end of file
rm(list = ls())
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Get data
ts = getData("tweets_raw.csv")[[2]]
#### Calculate rolling window statistics for ts ####
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew  = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
#### Test getRunningSD function ####
# Test whether getRunningSD function and for-loop calculating standard
# deviation with standard package functions generate same results
# Set tolerance for deviations between results (Smaller deviations
# are assumed to be due to accumulated rounding differences)
tol = 1e-15
# Iterate through window sizes
for(ws in 3:floor(length(ts)/2)) {
# Lag-1-autocorrelation
run_sd_acf  = getRunningSD(acf, ws)
run_sd_acf2 = rep(NA, nrow(acf))
for (i in (ws+1):nrow(acf)) {
run_sd_acf2[i] = sd(acf[ws:i, ws-1])
}
print(paste("Window size "%&%ws%&%":"))
print(paste("Lag-1-autocorrelation ->",
if(max(abs(run_sd_acf-run_sd_acf2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(run_sd_acf-run_sd_acf2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Variance
run_sd_var  = getRunningSD(var, ws)
run_sd_var2 = rep(NA, nrow(var))
for (i in (ws+1):nrow(var)) {
run_sd_var2[i] = sd(var[ws:i, ws-1])
}
print(paste("Variance              ->",
if(max(abs(run_sd_var-run_sd_var2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(run_sd_var-run_sd_var2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Skewness
run_sd_skew  = getRunningSD(skew, ws)
run_sd_skew2 = rep(NA, nrow(skew))
for (i in (ws+1):nrow(skew)) {
run_sd_skew2[i] = sd(skew[ws:i, ws-1])
}
print(paste("Skewness              ->",
if(max(abs(run_sd_skew-run_sd_skew2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between FFT and brute",
"force approach is: "%&%max(abs(run_sd_skew-run_sd_skew2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Tidy up after each window size
rm(ws, list = ls(pattern = "run_"))
}
rm(list = ls())
# Source custom functions
function.sources = list.files(pattern = "(TSAfun_){1}.*.R")
sapply(function.sources, source, .GlobalEnv)
# Function for easy string pasting
"%&%" = function(x, y) paste(x, y, sep = "")
# Get data
ts = getData("tweets_raw.csv")[[2]]
#### Calculate rolling window statistics for ts ####
# Set maximium window size
max.ws = floor(length(ts)/2)
# Lag-1-autocorrelation
acf = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowACF(ts, w = i)
acf  = data.frame(acf, c(rep(NA, i-1), temp))
colnames(acf)[ncol(acf)] = "acf_ws"%&%i
}
# Variance
var = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowVAR(ts, w = i)
var  = data.frame(var, c(rep(NA, i-1), temp))
colnames(var)[ncol(var)] = "var_ws"%&%i
}
# Skewness
skew = c(1:length(ts))
for(i in 3:max.ws) {
temp = getMovingWindowSKEW(ts, w = i)
skew  = data.frame(skew, c(rep(NA, i-1), temp))
colnames(skew)[ncol(skew)] = "skew_ws"%&%i
}
#### Test getRunningSD function ####
# Test whether getRunningSD function and for-loop calculating standard
# deviation with standard package functions generate same results
# Set tolerance for deviations between results (Smaller deviations
# are assumed to be due to accumulated rounding differences)
tol = 1e-15
# Iterate through window sizes
for(ws in 3:floor(length(ts)/2)) {
# Lag-1-autocorrelation
run_sd_acf  = getRunningSD(acf, ws)
run_sd_acf2 = rep(NA, nrow(acf))
for (i in (ws+1):nrow(acf)) {
run_sd_acf2[i] = sd(acf[ws:i, ws-1])
}
print(paste("Window size "%&%ws%&%":"))
print(paste("Lag-1-autocorrelation ->",
if(max(abs(run_sd_acf-run_sd_acf2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between getRunningSD",
"and for-loop is: "%&%max(abs(run_sd_acf-run_sd_acf2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Variance
run_sd_var  = getRunningSD(var, ws)
run_sd_var2 = rep(NA, nrow(var))
for (i in (ws+1):nrow(var)) {
run_sd_var2[i] = sd(var[ws:i, ws-1])
}
print(paste("Variance              ->",
if(max(abs(run_sd_var-run_sd_var2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between getRunningSD",
"and for-loop is: "%&%max(abs(run_sd_var-run_sd_var2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Skewness
run_sd_skew  = getRunningSD(skew, ws)
run_sd_skew2 = rep(NA, nrow(skew))
for (i in (ws+1):nrow(skew)) {
run_sd_skew2[i] = sd(skew[ws:i, ws-1])
}
print(paste("Skewness              ->",
if(max(abs(run_sd_skew-run_sd_skew2), na.rm = TRUE) > tol) {
paste("The maximum absolute deviation between getRunningSD",
"and for-loop is: "%&%max(abs(run_sd_skew-run_sd_skew2),
na.rm = TRUE))
} else {
paste("All deviations are smaller than "%&%tol)
}
))
# Tidy up after each window size
rm(ws, list = ls(pattern = "run_"))
}
# needed only for package installation or update
library(devtools)
devtools::install_github("lborke/yamldebugger")
# load the package every time you want to use 'yamldebugger'
library(yamldebugger)
allKeywords
"plot" %in% allKeywords
help(yaml.debugger.init)
d_init = yaml.debugger.init("c:/test", show_keywords = TRUE)
help(yaml.debugger.get.qnames)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
workdir = "../"
workdir
setwd("../")
workdir = getwd
workdir
workdir = getwd()
workdir
d_init = yaml.debugger.init(workdir, show_keywords = TRUE)
qnames = yaml.debugger.get.qnames(d_init$RootPath)
d_results = yaml.debugger.run(qnames, d_init)
OverView = yaml.debugger.summary(qnames, d_results, summaryType = "mini")
yaml.debugger.run()
yaml.debugger.run(
yaml.debugger.run
yaml.debugger.run
library(formatR)
tidy_source()
